<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Power curve</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body>

<table width="100%" summary="page for mxPowerSearch {OpenMx}"><tr><td>mxPowerSearch {OpenMx}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>Power curve</h2>

<h3>Description</h3>

<p>Determine the power curve between true and false models
</p>


<h3>Usage</h3>

<pre>
mxPowerSearch(trueModel, falseModel, n=NULL, sig.level=0.05, ...,
                    probes=300L, previousRun=NULL,
                    gdFun=mxGenerateData,
                    method=c('empirical', 'ncp'),
                    grid=NULL,
                    statistic=c('LRT','AIC','BIC'),
		    OK=mxOption(trueModel, "Status OK"),
		checkHess=FALSE,
		silent=!interactive())

mxPower(trueModel, falseModel, n=NULL, sig.level=0.05, power=0.8, ...,
                    probes=300L, gdFun=mxGenerateData,
                    method=c('empirical', 'ncp'),
                    statistic=c('LRT','AIC','BIC'),
                    OK=mxOption(trueModel, "Status OK"), checkHess=FALSE,
                    silent=!interactive())
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>trueModel</code></td>
<td>
<p>The true generating model for the data.</p>
</td></tr>
<tr valign="top"><td><code>falseModel</code></td>
<td>
<p>The model representing the null hypothesis that we
wish to reject.</p>
</td></tr>
<tr valign="top"><td><code>n</code></td>
<td>
<p>Average group sample size. When NULL, finds the relationship
between sample size and power. When given, finds the relationship
between a parameter and power (at the given sample size).</p>
</td></tr>
<tr valign="top"><td><code>sig.level</code></td>
<td>
<p>The false positive rate (a.k.a. type 1 error).</p>
</td></tr>
<tr valign="top"><td><code>power</code></td>
<td>
<p>The power (a.k.a. 1 - type 2 error).</p>
</td></tr>
<tr valign="top"><td><code>...</code></td>
<td>
<p>Not used.</p>
</td></tr>
<tr valign="top"><td><code>probes</code></td>
<td>
<p>The number of probes to use when
method=&lsquo;empirical&rsquo;.</p>
</td></tr>
<tr valign="top"><td><code>previousRun</code></td>
<td>
<p>Output from a prior run of &lsquo;mxPowerSearch&rsquo; to extend.</p>
</td></tr>
<tr valign="top"><td><code>gdFun</code></td>
<td>
<p>The function invoked to generate new data for each Monte
Carlo probe.</p>
</td></tr>
<tr valign="top"><td><code>method</code></td>
<td>
<p>To estimate power using the Monte Carlo method
(&lsquo;empirical&rsquo;) or the average non-centrality method
(&lsquo;ncp&rsquo;).</p>
</td></tr>
<tr valign="top"><td><code>grid</code></td>
<td>
<p>A vector of locations at which to evaluate the power. If
not provided, a reasonable default will be chosen.</p>
</td></tr>
<tr valign="top"><td><code>statistic</code></td>
<td>
<p>Which test to use to compare models.</p>
</td></tr>
<tr valign="top"><td><code>OK</code></td>
<td>
<p>The set of status code that are considered successful</p>
</td></tr>
<tr valign="top"><td><code>checkHess</code></td>
<td>
<p>Whether to approximate the Hessian in each
replication</p>
</td></tr>
<tr valign="top"><td><code>silent</code></td>
<td>
<p>Whether to output a progress indicator.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Power is the chance of obtaining a significant difference when there
is a significant difference (1 - false negative rate).
The likelihood ratio test is used by default. There are two
methods available to produce a power curve. The default,
<code>method=empirical</code>, works for any model where the likelihood
ratio test works. For example, definition variables and missing data
are fine, but parameters estimated at upper or lower bounds will cause
problems. The <code>method=empirical</code> can require a lot of time
because the models need to be fit 100s of times. An alternate
approach, <code>method=ncp</code>, is much more efficient and takes
advantage of the fact that the non-null distribution of likelihood
ratio test statistic is often <i>&chi;^2(df_1 - df_0, N &lambda;),
  chi^2(df1 - df0, N lambda)</i>. That is, the non-centrality parameter,
<i>&lambda;,lambda</i>, can be assumed, on average, to
contribute equally per row. This permits essentially instant power curves
without the burden of tedious simulation. However, definition
variables, missing data, or unconventional models (e.g., mixture
distributions) can violate this assumption. Therefore, we recommend
verifying that the output from <code>method=empirical</code> roughly matches
<code>method=ncp</code> on the model of interest before relying on
<code>method=ncp</code>. Unlike <code>method=empirical</code>, <code>method=ncp</code>
does not use the <code>gdFun</code> argument and works with models that
only have summary statistics for data.
</p>
<p>When <code>method=ncp</code>, parameters of both &lsquo;trueModel&rsquo; and
&lsquo;falseModel&rsquo; are assumed to be converged to
their desired values.
In contrast, when <code>method=empirical</code>, &lsquo;trueModel&rsquo;
need not be run or even contain data. On each replication,
data are generated from &lsquo;trueModel&rsquo; at the given parameter
vector. Both &lsquo;trueModel&rsquo; and &lsquo;falseModel&rsquo; are
fit against these data.
</p>
<p>When <code>statistic='LRT'</code> then the models must be nested and
<code>sig.level</code> is used to determine whether the test is rejected.
For &lsquo;AIC&rsquo; and &lsquo;BIC&rsquo;, the test is regarded as rejected
when the &lsquo;trueModel&rsquo; obtains a lower score than the
&lsquo;falseModel&rsquo;. In contrast to <code>statistic='LRT'</code>, there is
no nesting requirement. For example, &lsquo;AIC&rsquo; can be used to
compare a &lsquo;trueModel&rsquo; against its corresponding saturated
model.
</p>

<p><code>mxPower</code> operates in many modes.
When power is passed as <code>NULL</code> then power is calculated
and returned.
When power (as a scalar or vector) is given then sample or effect size
is (are) returned.
If you pass a list of models for &lsquo;falseModel&rsquo;, each model
will be checked in turn and the results returned as a vector.
If you pass a vector of sample sizes, each sample size will
be checked in turn and the results returns as a vector.
</p>
<p>In constrast to <code>mxPower</code>, <code>mxPowerSearch</code> attempts to model
the whole relationship between sample size or effect size and power.
A naive Monte Carlo estimate of power examines a single candidate
sample size at a time.  To obtain the whole curve, and simultaneously,
to reduce the number of simulation probes, <code>mxPowerSearch</code>
employs a binomial family generalized linear model with a logit link
to predict the power curve across the sample sizes of interest
(similar to Schoemann et al, 2014).
</p>
<p>The <code>mxPowerSearch</code> algorithm works in 3
stages. Without loss of generality, our description will assume a
sample size to power relationship, but a similar process is used for
the parameter value to power relationship. In the first stage, a crude
binary search is used to find the range reasonable values for N. This
stage is complete once we have at least two rejections and at least two
non-rejections. At this point, the binomial intercept and slope model
is fit to these data. If the <em>p</em>-value for the slope is less than
0.25 then we jump to stage 3. Otherwise, we fit an intercept only
binomial model. Our goal is to nail down the intercept (where
power=0.5) because this is the easiest point to find and is a
necessary prerequisite to estimate the variance (a.k.a. slope).
Therefore, we probe at the median of previous probes stepping by 10%
in the direction of the model's predicted intercept. Eventually, after enough
probes, we reach stage 3 where the <em>p</em>-value for the slope is
less than 0.25. At stage 3, our goal is to nail down the interesting
part of the power curve. Therefore, we cycle serially through probes
at 0, 1, and 2 logits from the intercept. This process is continued
for the permitted number of <code>probes</code>.
Occasionally, the <em>p</em>-value for the slope in the stage 3 model
grows larger than 0.25. In this case, we switch back to stage 2
(intercept only) until the stage 3 model start working again.
There is no other
convergence criteria. Accuracy continues to improves until the probe
limit is reached. After <code>mxPowerSearch</code> returns, additional probes can
be run by passing the previous result back into the function as the
<code>previousRun</code> argument.
</p>
<p>When &lsquo;n&rsquo; is fixed then <code>mxPowerSearch</code> helps answer the
question, &ldquo;how small of a true effect is likely to be detected
at a particular sample size?&rdquo; Only one parameter can be considered at
a time.  The way the simulation works is that a candidate value for
the parameter of interest is loaded into the <code>trueModel</code>, data
are generated, then both the true and false model are fit to the data to
obtain the difference in fit. The candidate parameter is initially set
to halfway between the <code>trueModel</code> and <code>falseModel</code>.  The
power curve will reflect the smallest distance, relative to the false
model, required to have a good chance to reject the false model
according to the chosen statistic.
</p>
<p>Note that the default <code>grid</code> is chosen to exhibit the interesting
part of the power curve (from 0.25 to 0.97).
Especially for <code>method=ncp</code>, this curve is practically
identical for any pair of models (but located at a different range of
sample sizes). You should select your own <code>grid</code> points if you
wish to align power curves from more than one power analysis.
</p>


<h3>Value</h3>

<p><code>mxPower</code> returns a vector of sample sizes, powers, or effect sizes.
</p>
<p><code>mxPowerSearch</code> returns a data.frame with one row for each &lsquo;grid&rsquo; point. The
first column is either the sample size &lsquo;N&rsquo; or the parameter
label. The second column is the power. The next two columns provide a
+/-2 SE confidence interval for the power as estimated by the binomial
logit linear model.
When <code>method=empirical</code> then the &lsquo;probes&rsquo; attribute
contains a data.frame record of the activity of the power estimation
process.
</p>


<h3>References</h3>

<p>Schoemann, A. M., Miller, P., Pornprasertmanit, S. &amp; Wu,
W. (2014). Using Monte Carlo simulations to determine power and sample
size for planned missing designs. <em>International Journal of
Behavioral Development, 38</em>(5), 471-479.
</p>


<h3>See Also</h3>

<p><code><a href="mxCompare.html">mxCompare</a></code>, <code><a href="omxSaturatedModel.html">mxRefModels</a></code>
</p>


<h3>Examples</h3>

<pre>
library(OpenMx)

data(demoOneFactor)
manifests &lt;- names(demoOneFactor)
latents &lt;- c("G")
factorModel &lt;- mxModel("One Factor",
                       type="RAM",
                       manifestVars = manifests,
                       latentVars = latents,
                       mxPath(from=latents, to=manifests, values=0.8),
                       mxPath(from=manifests, arrows=2,values=1),
                       mxPath(from=latents, arrows=2,
                              free=FALSE, values=1.0),
                       mxPath(from="one", to=manifests),
                       mxData(demoOneFactor, type="raw"))
factorModelFit &lt;- mxRun(factorModel)

indModel &lt;- factorModelFit
indModel$A$values['x1','G'] &lt;- 0.3
indModel$A$free['x1','G'] &lt;- FALSE
indModel &lt;- mxRun(indModel)

mxPowerSearch(factorModelFit, indModel, method='ncp')

mxPower(factorModelFit, indModel, method='ncp')
</pre>

<hr /><div style="text-align: center;">[Package <em>OpenMx</em> version 2.9.9 <a href="00Index.html">Index</a>]</div>
</body></html>
